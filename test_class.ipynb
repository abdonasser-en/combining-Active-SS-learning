{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from preprocess.dataset import get_MNIST,get_dataset,get_handler\n",
    "from models.model import Model\n",
    "from al_methods.random_sampling import RandomSampling\n",
    "from ssl_methods.semi_fixmatch import fixmatch\n",
    "import models\n",
    "from torchvision import transforms\n",
    "from framework.framework2 import Framework2\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the main \n",
    "X_tr, Y_tr, X_te, Y_te = get_dataset(\"Mnist\", \"./datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the main \n",
    "if type(X_tr) is list:\n",
    "    X_tr = np.array(X_tr)\n",
    "    Y_tr = torch.tensor(np.array(Y_tr))\n",
    "    X_te = np.array(X_te)\n",
    "    Y_te = torch.tensor(np.array(Y_te))\n",
    "\n",
    "if type(X_tr[0]) is not np.ndarray:\n",
    "    X_tr = X_tr.numpy()\n",
    "    X_te = X_te.numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 90 600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False,  True, False])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the main\n",
    "n_pool = len(Y_tr)\n",
    "n_test = len(Y_te)\n",
    "#in the main\n",
    "handler = get_handler(\"mnist\")\n",
    "# main or framewrok to see\n",
    "nEnd=100 # total number to query \n",
    "nQuery=1 # nombre of points to query in batch \n",
    "nStart=10 # nbre of points to start\n",
    "NUM_INIT_LB = int(nStart*n_pool/100)\n",
    "NUM_QUERY = int(nQuery*n_pool/100) if nStart!= 100 else 0\n",
    "NUM_ROUND = int((int(nEnd*n_pool/100) - NUM_INIT_LB)/ NUM_QUERY) if nStart!= 100 else 0\n",
    "if NUM_QUERY != 0:\n",
    "    if (int(nEnd*n_pool/100) - NUM_INIT_LB)% NUM_QUERY != 0:\n",
    "        NUM_ROUND += 1\n",
    "print(NUM_INIT_LB,NUM_ROUND,NUM_QUERY)\n",
    "model_name = sorted(name for name in models.__dict__ \n",
    "                    if callable(models.__dict__[name]))\n",
    "model_name\n",
    "model=Model('resnet50').get_model()\n",
    "model\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # Conversion en 3 canaux\n",
    "model.fc = torch.nn.Linear(2048, 10)  # Modifier la couche de classification pour 10 classes\n",
    "# in the main file\n",
    "idxs_lb = np.zeros(n_pool, dtype=bool)\n",
    "idxs_lb\n",
    "# in the main file\n",
    "idxs_tmp = np.arange(n_pool)\n",
    "idxs_tmp\n",
    "np.random.shuffle(idxs_tmp)\n",
    "idxs_tmp\n",
    "# in the main file\n",
    "idxs_lb[idxs_tmp[:NUM_INIT_LB]] = True\n",
    "idxs_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_pool = {'mnist':\n",
    "                { \n",
    "                 'n_class':10,\n",
    "                 'channels':1,\n",
    "                 'size': 28,\n",
    "                 'transform_tr': transforms.Compose([\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "                 'transform_te': transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "                 'loader_tr_args':{'batch_size': 128, 'num_workers': 8},\n",
    "                 'loader_te_args':{'batch_size': 1024, 'num_workers': 8},\n",
    "                 'normalize':{'mean': (0.1307,), 'std': (0.3081,)},\n",
    "                },\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self,n_class,img_size,channels,transform_tr,transform_te,loader_tr_args,loader_te_args,normalize):\n",
    "        self.n_class=n_class\n",
    "        self.img_size=img_size\n",
    "        self.channels=channels\n",
    "        self.transform_tr=transform_tr\n",
    "        self.transform_te=transform_te\n",
    "        self.loader_tr_args=loader_tr_args\n",
    "        self.loader_te_args=loader_te_args\n",
    "        self.normalize=normalize\n",
    "        self.dataset='mnist'\n",
    "        self.save_path='./save'\n",
    "        self.model='ResNet50'\n",
    "        self.lr=0.1\n",
    "        self.schedule = [20, 40]\n",
    "        self.momentum=0.9\n",
    "        self.gammas=[0.1,0.1]\n",
    "        self.strategy='framwork1'\n",
    "        self.optimizer='SGD'\n",
    "        self.save_model=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_args = args_pool[\"mnist\"]\n",
    "n_class = dataset_args['n_class']\n",
    "img_size = dataset_args['size']\n",
    "channels = dataset_args['channels']\n",
    "transform_tr = dataset_args['transform_tr']\n",
    "transform_te = dataset_args['transform_te']\n",
    "loader_tr_args = dataset_args['loader_tr_args']\n",
    "loader_te_args = dataset_args['loader_te_args']\n",
    "normalize = dataset_args['normalize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args=Args(n_class,img_size,channels,transform_tr,transform_te,loader_tr_args,loader_te_args,normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# al_strat=RandomSampling(X_tr, Y_tr, X_te, Y_te, idxs_lb, model, handler, args)\n",
    "# ssl_strat=fixmatch(X_tr, Y_tr, X_te, Y_te, idxs_lb, model, handler, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_2= Framework2(X_tr, Y_tr, X_te, Y_te, idxs_lb, model, handler, args,RandomSampling,fixmatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPUs!\n",
      "[Batch=000] [Loss=2.59]\n",
      "[Batch=010] [Loss=11.40]\n",
      "[Batch=020] [Loss=2.31]\n",
      "[Batch=030] [Loss=2.13]\n",
      "[Batch=040] [Loss=12.44]\n",
      "\n",
      "==>>[2023-08-18 07:46:48] [Epoch=000/010] [framwork1 Need: 00:00:00] [LR=0.1000] [Best : Test Accuracy=0.00, Error=1.00]\n",
      "[Batch=000] [Loss=2.11]\n",
      "[Batch=010] [Loss=2.09]\n",
      "[Batch=020] [Loss=1.96]\n",
      "[Batch=030] [Loss=20.55]\n",
      "[Batch=040] [Loss=12.35]\n",
      "\n",
      "==>>[2023-08-18 07:46:52] [Epoch=001/010] [framwork1 Need: 00:00:40] [LR=0.1000] [Best : Test Accuracy=0.13, Error=0.87]\n",
      "[Batch=000] [Loss=4.67]\n",
      "[Batch=010] [Loss=15.57]\n",
      "[Batch=020] [Loss=3.16]\n",
      "[Batch=030] [Loss=6.85]\n",
      "[Batch=040] [Loss=24.76]\n",
      "\n",
      "==>>[2023-08-18 07:46:55] [Epoch=002/010] [framwork1 Need: 00:00:30] [LR=0.1000] [Best : Test Accuracy=0.13, Error=0.87]\n",
      "[Batch=000] [Loss=1.85]\n",
      "[Batch=010] [Loss=1.87]\n",
      "[Batch=020] [Loss=1.84]\n",
      "[Batch=030] [Loss=12.39]\n",
      "[Batch=040] [Loss=9.47]\n",
      "\n",
      "==>>[2023-08-18 07:46:58] [Epoch=003/010] [framwork1 Need: 00:00:24] [LR=0.1000] [Best : Test Accuracy=0.25, Error=0.75]\n",
      "[Batch=000] [Loss=2.12]\n",
      "[Batch=010] [Loss=2.09]\n",
      "[Batch=020] [Loss=2.13]\n",
      "[Batch=030] [Loss=3.67]\n",
      "[Batch=040] [Loss=1.70]\n",
      "\n",
      "==>>[2023-08-18 07:47:01] [Epoch=004/010] [framwork1 Need: 00:00:20] [LR=0.1000] [Best : Test Accuracy=0.25, Error=0.75]\n",
      "[Batch=000] [Loss=1.77]\n",
      "[Batch=010] [Loss=1.46]\n",
      "[Batch=020] [Loss=1.36]\n",
      "[Batch=030] [Loss=1.54]\n",
      "[Batch=040] [Loss=1.26]\n",
      "\n",
      "==>>[2023-08-18 07:47:04] [Epoch=005/010] [framwork1 Need: 00:00:16] [LR=0.1000] [Best : Test Accuracy=0.32, Error=0.68]\n",
      "[Batch=000] [Loss=1.31]\n",
      "[Batch=010] [Loss=2.10]\n",
      "[Batch=020] [Loss=1.17]\n",
      "[Batch=030] [Loss=1.16]\n",
      "[Batch=040] [Loss=0.95]\n",
      "\n",
      "==>>[2023-08-18 07:47:07] [Epoch=006/010] [framwork1 Need: 00:00:13] [LR=0.1000] [Best : Test Accuracy=0.60, Error=0.40]\n",
      "[Batch=000] [Loss=0.89]\n",
      "[Batch=010] [Loss=0.95]\n",
      "[Batch=020] [Loss=0.72]\n",
      "[Batch=030] [Loss=0.65]\n",
      "[Batch=040] [Loss=0.57]\n",
      "\n",
      "==>>[2023-08-18 07:47:10] [Epoch=007/010] [framwork1 Need: 00:00:09] [LR=0.1000] [Best : Test Accuracy=0.63, Error=0.37]\n",
      "[Batch=000] [Loss=0.83]\n",
      "[Batch=010] [Loss=0.72]\n",
      "[Batch=020] [Loss=0.67]\n",
      "[Batch=030] [Loss=0.82]\n",
      "[Batch=040] [Loss=0.53]\n",
      "\n",
      "==>>[2023-08-18 07:47:13] [Epoch=008/010] [framwork1 Need: 00:00:06] [LR=0.1000] [Best : Test Accuracy=0.77, Error=0.23]\n",
      "[Batch=000] [Loss=0.44]\n",
      "[Batch=010] [Loss=0.66]\n",
      "[Batch=020] [Loss=0.64]\n",
      "[Batch=030] [Loss=0.48]\n",
      "[Batch=040] [Loss=0.50]\n",
      "\n",
      "==>>[2023-08-18 07:47:16] [Epoch=009/010] [framwork1 Need: 00:00:03] [LR=0.1000] [Best : Test Accuracy=0.80, Error=0.20]\n",
      "---- save figure the accuracy/loss curve of train/val into ./save/mnist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8105"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framework_2.train(2e-3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc=framework_2.predict(X_te,Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8105"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.zeros(NUM_ROUND+1)\n",
    "acc[0] = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/90\n",
      "Let's use 1 GPUs!\n",
      "[Batch=000] [Loss=1.06]\n",
      "[Batch=010] [Loss=0.77]\n",
      "[Batch=020] [Loss=0.80]\n",
      "\n",
      "==>>[2023-08-18 07:47:41] [Epoch=000/010] [framwork1 Need: 00:00:00] [LR=0.1000] [Best : Test Accuracy=0.00, Error=1.00]\n",
      "[Batch=000] [Loss=0.75]\n",
      "[Batch=010] [Loss=0.93]\n",
      "[Batch=020] [Loss=0.65]\n",
      "\n",
      "==>>[2023-08-18 07:48:05] [Epoch=001/010] [framwork1 Need: 00:03:33] [LR=0.1000] [Best : Test Accuracy=0.85, Error=0.15]\n",
      "[Batch=000] [Loss=0.80]\n",
      "[Batch=010] [Loss=0.81]\n",
      "[Batch=020] [Loss=0.75]\n",
      "\n",
      "==>>[2023-08-18 07:48:29] [Epoch=002/010] [framwork1 Need: 00:03:10] [LR=0.1000] [Best : Test Accuracy=0.85, Error=0.15]\n",
      "[Batch=000] [Loss=0.70]\n",
      "[Batch=010] [Loss=0.69]\n",
      "[Batch=020] [Loss=0.77]\n",
      "\n",
      "==>>[2023-08-18 07:48:54] [Epoch=003/010] [framwork1 Need: 00:02:47] [LR=0.1000] [Best : Test Accuracy=0.87, Error=0.13]\n",
      "[Batch=000] [Loss=0.76]\n",
      "[Batch=010] [Loss=0.76]\n",
      "[Batch=020] [Loss=0.76]\n",
      "\n",
      "==>>[2023-08-18 07:49:18] [Epoch=004/010] [framwork1 Need: 00:02:24] [LR=0.1000] [Best : Test Accuracy=0.89, Error=0.11]\n",
      "[Batch=000] [Loss=0.75]\n",
      "[Batch=010] [Loss=0.77]\n",
      "[Batch=020] [Loss=0.73]\n",
      "\n",
      "==>>[2023-08-18 07:49:42] [Epoch=005/010] [framwork1 Need: 00:02:00] [LR=0.1000] [Best : Test Accuracy=0.89, Error=0.11]\n",
      "[Batch=000] [Loss=0.64]\n",
      "[Batch=010] [Loss=0.73]\n",
      "[Batch=020] [Loss=0.70]\n",
      "\n",
      "==>>[2023-08-18 07:50:06] [Epoch=006/010] [framwork1 Need: 00:01:36] [LR=0.1000] [Best : Test Accuracy=0.89, Error=0.11]\n",
      "[Batch=000] [Loss=0.75]\n",
      "[Batch=010] [Loss=0.73]\n",
      "[Batch=020] [Loss=0.67]\n",
      "\n",
      "==>>[2023-08-18 07:50:31] [Epoch=007/010] [framwork1 Need: 00:01:12] [LR=0.1000] [Best : Test Accuracy=0.89, Error=0.11]\n",
      "[Batch=000] [Loss=0.72]\n",
      "[Batch=010] [Loss=0.65]\n",
      "[Batch=020] [Loss=0.73]\n",
      "\n",
      "==>>[2023-08-18 07:50:55] [Epoch=008/010] [framwork1 Need: 00:00:48] [LR=0.1000] [Best : Test Accuracy=0.91, Error=0.09]\n",
      "[Batch=000] [Loss=0.72]\n",
      "[Batch=010] [Loss=0.73]\n",
      "[Batch=020] [Loss=0.76]\n",
      "\n",
      "==>>[2023-08-18 07:51:20] [Epoch=009/010] [framwork1 Need: 00:00:24] [LR=0.1000] [Best : Test Accuracy=0.91, Error=0.09]\n",
      "---- save figure the accuracy/loss curve of train/val into ./save/mnist\n",
      "Round 2/90\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomSampling' object has no attribute 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# query\u001b[39;00m\n\u001b[1;32m     11\u001b[0m ts \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 12\u001b[0m output \u001b[39m=\u001b[39m framework_2\u001b[39m.\u001b[39;49mstratAl\u001b[39m.\u001b[39;49mquery(NUM_QUERY)\n\u001b[1;32m     13\u001b[0m q_idxs \u001b[39m=\u001b[39m output\n\u001b[1;32m     14\u001b[0m idxs_lb[q_idxs] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomSampling' object has no attribute 'query'"
     ]
    }
   ],
   "source": [
    "for rd in range(1, NUM_ROUND+1):\n",
    "\n",
    "    if rd%2==0:\n",
    "        # Al_methods\n",
    "        print('Round {}/{}'.format(rd, NUM_ROUND), flush=True)\n",
    "        labeled = len(np.arange(n_pool)[idxs_lb])\n",
    "        if NUM_QUERY > int(nEnd*n_pool/100) - labeled:\n",
    "            NUM_QUERY = int(nEnd*n_pool/100) - labeled\n",
    "            \n",
    "        # query\n",
    "        ts = time.time()\n",
    "        output = framework_2.stratAl.query(NUM_QUERY)\n",
    "        q_idxs = output\n",
    "        idxs_lb[q_idxs] = True\n",
    "        te = time.time()\n",
    "        tp = te - ts\n",
    "        \n",
    "        # update\n",
    "        framework_2.update(idxs_lb)\n",
    "        best_test_acc = framework_2.train(alpha=2e-3, n_epoch=10)\n",
    "\n",
    "        t_iter = time.time() - ts\n",
    "        \n",
    "        # round accuracy\n",
    "        # test_acc = strategy.predict(X_te, Y_te)\n",
    "        acc[rd] = best_test_acc\n",
    "    else:\n",
    "        #SSL methods\n",
    "        \n",
    "        print('Round {}/{}'.format(rd, NUM_ROUND), flush=True)\n",
    "        labeled = len(np.arange(n_pool)[idxs_lb])\n",
    "        if NUM_QUERY > int(nEnd*n_pool/100) - labeled:\n",
    "            NUM_QUERY = int(nEnd*n_pool/100) - labeled\n",
    "            \n",
    "        # query\n",
    "        ts = time.time()\n",
    "\n",
    "        output = framework_2.stratSSL.query(NUM_QUERY)\n",
    "        q_idxs = output\n",
    "        idxs_lb[q_idxs] = True\n",
    "        te = time.time()\n",
    "        tp = te - ts\n",
    "        \n",
    "        # update\n",
    "        framework_2.update(idxs_lb)\n",
    "        best_test_acc = framework_2.stratSSL.train(alpha=2e-3, n_epoch=10)\n",
    "\n",
    "        t_iter = time.time() - ts\n",
    "        \n",
    "        # round accuracy\n",
    "        # test_acc = strategy.predict(X_te, Y_te)\n",
    "        acc[rd] = best_test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
