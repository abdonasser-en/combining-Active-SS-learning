{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from preprocess.dataset import get_MNIST,get_dataset,get_handler\n",
    "from models.model import Model\n",
    "from al_methods.least_confidence import LeastConfidence\n",
    "from ssl_methods.semi_fixmatch import fixmatch\n",
    "import models\n",
    "from torchvision import transforms\n",
    "from framework.framework2 import Framework2\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.spatial.distance import jensenshannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the main \n",
    "X_tr, Y_tr, X_te, Y_te = get_dataset(\"Mnist\", \"./datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the main \n",
    "if type(X_tr) is list:\n",
    "    X_tr = np.array(X_tr)\n",
    "    Y_tr = torch.tensor(np.array(Y_tr))\n",
    "    X_te = np.array(X_te)\n",
    "    Y_te = torch.tensor(np.array(Y_te))\n",
    "\n",
    "if type(X_tr[0]) is not np.ndarray:\n",
    "    X_tr = X_tr.numpy()\n",
    "    X_te = X_te.numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 40 600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the main\n",
    "n_pool = len(Y_tr)\n",
    "n_test = len(Y_te)\n",
    "#in the main\n",
    "handler = get_handler(\"mnist\")\n",
    "# main or framewrok to see\n",
    "nEnd=50 # total number to query \n",
    "nQuery=1 # nombre of points to query in batch \n",
    "nStart=10 # nbre of points to start\n",
    "NUM_INIT_LB = int(nStart*n_pool/100)\n",
    "NUM_QUERY = int(nQuery*n_pool/100) if nStart!= 100 else 0\n",
    "NUM_ROUND = int((int(nEnd*n_pool/100) - NUM_INIT_LB)/ NUM_QUERY) if nStart!= 100 else 0\n",
    "if NUM_QUERY != 0:\n",
    "    if (int(nEnd*n_pool/100) - NUM_INIT_LB)% NUM_QUERY != 0:\n",
    "        NUM_ROUND += 1\n",
    "print(NUM_INIT_LB,NUM_ROUND,NUM_QUERY)\n",
    "model_name = sorted(name for name in models.__dict__ \n",
    "                    if callable(models.__dict__[name]))\n",
    "model_name\n",
    "model=Model('resnet50').get_model()\n",
    "model\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # Conversion en 3 canaux\n",
    "model.fc = torch.nn.Linear(2048, 10)  # Modifier la couche de classification pour 10 classes\n",
    "# in the main file\n",
    "idxs_lb = np.zeros(n_pool, dtype=bool)\n",
    "idxs_lb\n",
    "# in the main file\n",
    "idxs_tmp = np.arange(n_pool)\n",
    "idxs_tmp\n",
    "np.random.shuffle(idxs_tmp)\n",
    "idxs_tmp\n",
    "# in the main file\n",
    "idxs_lb[idxs_tmp[:NUM_INIT_LB]] = True\n",
    "idxs_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idxs_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idxs_lb[idxs_lb==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_pool = {'mnist':\n",
    "                { \n",
    "                 'n_class':10,\n",
    "                 'channels':1,\n",
    "                 'size': 28,\n",
    "                 'transform_tr': transforms.Compose([\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "                 'transform_te': transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "                 'loader_tr_args':{'batch_size': 128, 'num_workers': 8},\n",
    "                 'loader_te_args':{'batch_size': 1024, 'num_workers': 8},\n",
    "                 'normalize':{'mean': (0.1307,), 'std': (0.3081,)},\n",
    "                },\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self,n_class,img_size,channels,transform_tr,transform_te,loader_tr_args,loader_te_args,normalize):\n",
    "        self.n_class=n_class\n",
    "        self.img_size=img_size\n",
    "        self.channels=channels\n",
    "        self.transform_tr=transform_tr\n",
    "        self.transform_te=transform_te\n",
    "        self.loader_tr_args=loader_tr_args\n",
    "        self.loader_te_args=loader_te_args\n",
    "        self.normalize=normalize\n",
    "        self.dataset='mnist'\n",
    "        self.save_path='./save'\n",
    "        self.model='ResNet50'\n",
    "        self.lr=0.1\n",
    "        self.schedule = [20, 40]\n",
    "        self.momentum=0.9\n",
    "        self.gammas=[0.1,0.1]\n",
    "        self.strategy='framwork1'\n",
    "        self.optimizer='SGD'\n",
    "        self.save_model=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_args = args_pool[\"mnist\"]\n",
    "n_class = dataset_args['n_class']\n",
    "img_size = dataset_args['size']\n",
    "channels = dataset_args['channels']\n",
    "transform_tr = dataset_args['transform_tr']\n",
    "transform_te = dataset_args['transform_te']\n",
    "loader_tr_args = dataset_args['loader_tr_args']\n",
    "loader_te_args = dataset_args['loader_te_args']\n",
    "normalize = dataset_args['normalize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args=Args(n_class,img_size,channels,transform_tr,transform_te,loader_tr_args,loader_te_args,normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# al_strat=RandomSampling(X_tr, Y_tr, X_te, Y_te, idxs_lb, model, handler, args)\n",
    "# ssl_strat=fixmatch(X_tr, Y_tr, X_te, Y_te, idxs_lb, model, handler, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_2= Framework2(X_tr, Y_tr, X_te, Y_te, idxs_lb, model, handler, args,LeastConfidence,fixmatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 1 GPUs!\n",
      "[Batch=000] [Loss=2.69]\n",
      "[Batch=010] [Loss=3.87]\n",
      "[Batch=020] [Loss=18.17]\n",
      "[Batch=030] [Loss=7.31]\n",
      "[Batch=040] [Loss=23.92]\n",
      "\n",
      "==>>[2023-08-21 15:42:11] [Epoch=000/010] [framwork1 Need: 00:00:00] [LR=0.1000] [Best : Test Accuracy=0.00, Error=1.00]\n",
      "[Batch=000] [Loss=11.89]\n",
      "[Batch=010] [Loss=8.08]\n",
      "[Batch=020] [Loss=2.21]\n",
      "[Batch=030] [Loss=2.21]\n",
      "[Batch=040] [Loss=4.57]\n",
      "\n",
      "==>>[2023-08-21 15:42:14] [Epoch=001/010] [framwork1 Need: 00:00:32] [LR=0.1000] [Best : Test Accuracy=0.15, Error=0.85]\n",
      "[Batch=000] [Loss=12.04]\n",
      "[Batch=010] [Loss=2.84]\n",
      "[Batch=020] [Loss=1.94]\n",
      "[Batch=030] [Loss=4.74]\n",
      "[Batch=040] [Loss=3.58]\n",
      "\n",
      "==>>[2023-08-21 15:42:17] [Epoch=002/010] [framwork1 Need: 00:00:25] [LR=0.1000] [Best : Test Accuracy=0.16, Error=0.84]\n",
      "[Batch=000] [Loss=2.65]\n",
      "[Batch=010] [Loss=3.72]\n",
      "[Batch=020] [Loss=1.75]\n",
      "[Batch=030] [Loss=1.76]\n",
      "[Batch=040] [Loss=1.74]\n",
      "\n",
      "==>>[2023-08-21 15:42:20] [Epoch=003/010] [framwork1 Need: 00:00:21] [LR=0.1000] [Best : Test Accuracy=0.26, Error=0.74]\n",
      "[Batch=000] [Loss=3.26]\n",
      "[Batch=010] [Loss=1.57]\n",
      "[Batch=020] [Loss=1.60]\n",
      "[Batch=030] [Loss=1.50]\n",
      "[Batch=040] [Loss=1.44]\n",
      "\n",
      "==>>[2023-08-21 15:42:22] [Epoch=004/010] [framwork1 Need: 00:00:18] [LR=0.1000] [Best : Test Accuracy=0.33, Error=0.67]\n",
      "[Batch=000] [Loss=1.48]\n",
      "[Batch=010] [Loss=1.30]\n",
      "[Batch=020] [Loss=1.27]\n",
      "[Batch=030] [Loss=1.26]\n",
      "[Batch=040] [Loss=1.25]\n",
      "\n",
      "==>>[2023-08-21 15:42:25] [Epoch=005/010] [framwork1 Need: 00:00:15] [LR=0.1000] [Best : Test Accuracy=0.43, Error=0.57]\n",
      "[Batch=000] [Loss=1.23]\n",
      "[Batch=010] [Loss=1.21]\n",
      "[Batch=020] [Loss=1.04]\n",
      "[Batch=030] [Loss=1.05]\n",
      "[Batch=040] [Loss=1.00]\n",
      "\n",
      "==>>[2023-08-21 15:42:28] [Epoch=006/010] [framwork1 Need: 00:00:11] [LR=0.1000] [Best : Test Accuracy=0.53, Error=0.47]\n",
      "[Batch=000] [Loss=0.86]\n",
      "[Batch=010] [Loss=1.00]\n",
      "[Batch=020] [Loss=0.96]\n",
      "[Batch=030] [Loss=0.63]\n",
      "[Batch=040] [Loss=0.66]\n",
      "\n",
      "==>>[2023-08-21 15:42:31] [Epoch=007/010] [framwork1 Need: 00:00:08] [LR=0.1000] [Best : Test Accuracy=0.64, Error=0.36]\n",
      "[Batch=000] [Loss=0.87]\n",
      "[Batch=010] [Loss=0.68]\n",
      "[Batch=020] [Loss=0.59]\n",
      "[Batch=030] [Loss=0.80]\n",
      "[Batch=040] [Loss=0.66]\n",
      "\n",
      "==>>[2023-08-21 15:42:34] [Epoch=008/010] [framwork1 Need: 00:00:05] [LR=0.1000] [Best : Test Accuracy=0.69, Error=0.31]\n",
      "[Batch=000] [Loss=0.73]\n",
      "[Batch=010] [Loss=0.51]\n",
      "[Batch=020] [Loss=0.42]\n",
      "[Batch=030] [Loss=0.60]\n",
      "[Batch=040] [Loss=1.21]\n",
      "\n",
      "==>>[2023-08-21 15:42:37] [Epoch=009/010] [framwork1 Need: 00:00:02] [LR=0.1000] [Best : Test Accuracy=0.69, Error=0.31]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './save/mnist.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m framework_2\u001b[39m.\u001b[39;49mtrain(\u001b[39m2e-3\u001b[39;49m,\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/combining-Active-SS-learning/strategy_utils_framework/strategy.py:153\u001b[0m, in \u001b[0;36mStrategy.train\u001b[0;34m(self, alpha, n_epoch)\u001b[0m\n\u001b[1;32m    151\u001b[0m             best_test_acc \u001b[39m=\u001b[39m test_acc\n\u001b[1;32m    152\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_model()\n\u001b[0;32m--> 153\u001b[0m     recorder\u001b[39m.\u001b[39;49mplot_curve(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49msave_path, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mdataset))\n\u001b[1;32m    154\u001b[0m     \u001b[39m# self.clf = self.clf.module\u001b[39;00m\n\u001b[1;32m    156\u001b[0m best_test_acc \u001b[39m=\u001b[39m recorder\u001b[39m.\u001b[39mmax_accuracy(istrain\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/combining-Active-SS-learning/strategy_utils_framework/utils.py:138\u001b[0m, in \u001b[0;36mRecorderMeter.plot_curve\u001b[0;34m(self, save_path)\u001b[0m\n\u001b[1;32m    134\u001b[0m plt\u001b[39m.\u001b[39mlegend(loc\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, fontsize\u001b[39m=\u001b[39mlegend_fontsize)\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m save_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     fig\u001b[39m.\u001b[39;49msavefig(save_path, dpi\u001b[39m=\u001b[39;49mdpi, bbox_inches\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtight\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    139\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m---- save figure \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m into \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(title, save_path))\n\u001b[1;32m    140\u001b[0m plt\u001b[39m.\u001b[39mclose(fig)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/figure.py:3378\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3374\u001b[0m     \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes:\n\u001b[1;32m   3375\u001b[0m         stack\u001b[39m.\u001b[39menter_context(\n\u001b[1;32m   3376\u001b[0m             ax\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39m_cm_set(facecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m, edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m-> 3378\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(fname, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     \u001b[39m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m     \u001b[39m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m     \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, dpi\u001b[39m=\u001b[39mdpi):\n\u001b[0;32m-> 2366\u001b[0m         result \u001b[39m=\u001b[39m print_method(\n\u001b[1;32m   2367\u001b[0m             filename,\n\u001b[1;32m   2368\u001b[0m             facecolor\u001b[39m=\u001b[39;49mfacecolor,\n\u001b[1;32m   2369\u001b[0m             edgecolor\u001b[39m=\u001b[39;49medgecolor,\n\u001b[1;32m   2370\u001b[0m             orientation\u001b[39m=\u001b[39;49morientation,\n\u001b[1;32m   2371\u001b[0m             bbox_inches_restore\u001b[39m=\u001b[39;49m_bbox_inches_restore,\n\u001b[1;32m   2372\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2373\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2228\u001b[0m     optional_kws \u001b[39m=\u001b[39m {  \u001b[39m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdpi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfacecolor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39medgecolor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39morientation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2230\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbbox_inches_restore\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m   2231\u001b[0m     skip \u001b[39m=\u001b[39m optional_kws \u001b[39m-\u001b[39m {\u001b[39m*\u001b[39minspect\u001b[39m.\u001b[39msignature(meth)\u001b[39m.\u001b[39mparameters}\n\u001b[0;32m-> 2232\u001b[0m     print_method \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mwraps(meth)(\u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: meth(\n\u001b[1;32m   2233\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m kwargs\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m skip}))\n\u001b[1;32m   2234\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     print_method \u001b[39m=\u001b[39m meth\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_png\u001b[39m(\u001b[39mself\u001b[39m, filename_or_obj, \u001b[39m*\u001b[39m, metadata\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pil_kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    463\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[39m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_print_pil(filename_or_obj, \u001b[39m\"\u001b[39;49m\u001b[39mpng\u001b[39;49m\u001b[39m\"\u001b[39;49m, pil_kwargs, metadata)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:458\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[39m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m FigureCanvasAgg\u001b[39m.\u001b[39mdraw(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 458\u001b[0m mpl\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mimsave(\n\u001b[1;32m    459\u001b[0m     filename_or_obj, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuffer_rgba(), \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49mfmt, origin\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mupper\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    460\u001b[0m     dpi\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdpi, metadata\u001b[39m=\u001b[39;49mmetadata, pil_kwargs\u001b[39m=\u001b[39;49mpil_kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/image.py:1689\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1687\u001b[0m pil_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mformat\u001b[39m)\n\u001b[1;32m   1688\u001b[0m pil_kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mdpi\u001b[39m\u001b[39m\"\u001b[39m, (dpi, dpi))\n\u001b[0;32m-> 1689\u001b[0m image\u001b[39m.\u001b[39;49msave(fname, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpil_kwargs)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:2209\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2207\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mr+b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2208\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2209\u001b[0m         fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mw+b\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2211\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2212\u001b[0m     save_handler(\u001b[39mself\u001b[39m, fp, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './save/mnist.png'"
     ]
    }
   ],
   "source": [
    "framework_2.train(2e-3,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a weakly data augmentation transform\n",
    "# weak_transform = transforms.Compose([\n",
    "#     transforms.RandomCrop(14),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# # Create a strongly data augmentation transform\n",
    "# strong_transform = transforms.Compose([\n",
    "#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "#     transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 0.1)),\n",
    "#     transforms.RandomPerspective(),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find indices where the boolean matrix is False\n",
    "# false_indices = np.argwhere(framework_2.idxs_lb == False).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U_X_tr=X_tr[false_indices]\n",
    "# U_Y_tr=Y_tr[false_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlabeled_data_weak=DataLoader(handler(U_X_tr,U_Y_tr,transform=weak_transform))\n",
    "# unlabeled_data_strong=DataLoader(handler(U_X_tr,U_Y_tr,transform=strong_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weakly augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net=framework_2.net.eval()\n",
    "# predictions_weak = []\n",
    "# with torch.no_grad():\n",
    "#     for x, _,_ in unlabeled_data_weak:\n",
    "#         # Move the batch to the appropriate device (CPU or GPU)\n",
    "#         x= x.to(framework_2.device)  # device could be 'cuda' or 'cpu'\n",
    "        \n",
    "#         # Forward pass to obtain predictions\n",
    "#         batch_predictions = net(x)\n",
    "        \n",
    "#         # Append batch predictions to the list\n",
    "#         predictions_weak.append(batch_predictions.cpu().numpy())  # Move predictions to CPU and convert to numpy\n",
    "\n",
    "# # Concatenate predictions from all batches\n",
    "# predictions_weak = np.concatenate(predictions_weak, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net=framework_2.net.eval()\n",
    "# predictions_strong = []\n",
    "# with torch.no_grad():\n",
    "#     for x, _,_ in unlabeled_data_strong:\n",
    "#         # Move the batch to the appropriate device (CPU or GPU)\n",
    "#         x= x.to(framework_2.device)  # device could be 'cuda' or 'cpu'\n",
    "        \n",
    "#         # Forward pass to obtain predictions\n",
    "#         batch_predictions = net(x)\n",
    "        \n",
    "#         # Append batch predictions to the list\n",
    "#         predictions_strong.append(batch_predictions.cpu().numpy())  # Move predictions to CPU and convert to numpy\n",
    "\n",
    "# # Concatenate predictions from all batches\n",
    "# predictions_strong = np.concatenate(predictions_strong, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jensen=jensenshannon(predictions_weak,predictions_strong,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(predictions_weak,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5*(np.max(predictions_weak,axis=1)+np.max(predictions_strong,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tot=(1-jensen ) *0.5*(np.max(predictions_weak,axis=1)+np.max(predictions_strong,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc=framework_2.predict(X_te,Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.zeros(NUM_ROUND+1)\n",
    "acc[0] = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rd in range(1, NUM_ROUND+1):\n",
    "\n",
    "    if rd%2==0:\n",
    "        # Al_methods\n",
    "        print('Round {}/{}'.format(rd, NUM_ROUND), flush=True)\n",
    "        labeled = len(np.arange(n_pool)[idxs_lb])\n",
    "        if NUM_QUERY > int(nEnd*n_pool/100) - labeled:\n",
    "            NUM_QUERY = int(nEnd*n_pool/100) - labeled\n",
    "            \n",
    "        # query\n",
    "        ts = time.time()\n",
    "        output = framework_2.stratAl.query(NUM_QUERY)\n",
    "        q_idxs = output\n",
    "        idxs_lb[q_idxs] = True\n",
    "        te = time.time()\n",
    "        tp = te - ts\n",
    "        \n",
    "        # update\n",
    "        framework_2.update(idxs_lb)\n",
    "        best_test_acc = framework_2.train(alpha=2e-3, n_epoch=10)\n",
    "\n",
    "        t_iter = time.time() - ts\n",
    "        \n",
    "        # round accuracy\n",
    "        # test_acc = strategy.predict(X_te, Y_te)\n",
    "        acc[rd] = best_test_acc\n",
    "    else:\n",
    "        #SSL methods\n",
    "        \n",
    "        print('Round {}/{}'.format(rd, NUM_ROUND), flush=True)\n",
    "        labeled = len(np.arange(n_pool)[idxs_lb])\n",
    "        if NUM_QUERY > int(nEnd*n_pool/100) - labeled:\n",
    "            NUM_QUERY = int(nEnd*n_pool/100) - labeled\n",
    "            \n",
    "        # query\n",
    "        ts = time.time()\n",
    "\n",
    "        output = framework_2.stratSSL.query(NUM_QUERY)\n",
    "        q_idxs = output\n",
    "        idxs_lb[q_idxs] = True\n",
    "        te = time.time()\n",
    "        tp = te - ts\n",
    "        \n",
    "        # update\n",
    "        framework_2.update(idxs_lb)\n",
    "        best_test_acc = framework_2.stratSSL.train(alpha=2e-3, n_epoch=10)\n",
    "\n",
    "        t_iter = time.time() - ts\n",
    "        \n",
    "        # round accuracy\n",
    "        # test_acc = strategy.predict(X_te, Y_te)\n",
    "        acc[rd] = best_test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"least_fix_acc.npy\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
